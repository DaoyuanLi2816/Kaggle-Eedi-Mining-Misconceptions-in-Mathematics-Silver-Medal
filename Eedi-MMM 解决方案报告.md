# Eedi - Mining Misconceptions in Mathematics 解决方案报告

## 竞赛概述

### 竞赛网址

https://www.kaggle.com/c/eedi-mining-misconceptions-in-mathematics

### 竞赛简介

本次竞赛旨在开发一个基于机器学习的自然语言处理（NLP）模型，能够准确预测数学选择题中错误选项（distractors）与潜在误解（misconceptions）之间的亲和力。该模型将为每个错误选项推荐候选的误解，帮助教育专家更高效地标注误解，提高标注的一致性和效率。

### 竞赛背景

在数学教育中，选择题（Diagnostic Question，DQ）通常包含一个正确答案和三个精心设计的错误选项（distractors），每个错误选项对应一个特定的学生误解。例如，一个学生选择了错误选项“13”，可能表明其存在“忽视运算优先级，从左到右依次进行运算”的误解。

手动为每个错误选项标注对应的误解既耗时又容易产生标注不一致的问题。此外，随着新知识领域的拓展，可能会不断发现新的误解。因此，开发一个能够自动推荐误解的模型显得尤为重要。



## 解决方案概述

本解决方案分为两个阶段：

1. **Retriever 阶段**：利用检索模型为每个错误选项推荐候选的误解。
2. **Reranker 阶段**：对Retriever推荐的候选误解的Top5，进行重新排序，提高推荐的准确性。

竞赛使用的评估指标是 **Mean Average Precision @ 25 (MAP@25)**，即对每个预测的误解列表计算平均精度，再对所有样本取平均值。



## 详细解决方案

### 一、数据预处理

#### 数据读取与转换

1. **读取数据**：

   - 使用 `polars` 库读取训练集和误解映射文件。
   - 将宽表格式的数据转换为长表格式，便于后续处理。

2. **生成长表格式**：

   - 

   - 对每个问题的四个选项（A、B、C、D）的文本进行展开，生成 `QuestionId_Answer` 和对应的 `AllText`。
   - `AllText`包含`ConstructName`、`SubjectName`、`QuestionText`、`CorrectAnswerText`和`WrongAnswerText`拼接成一个统一的文本字段，以便模型进行上下文理解。
   - 将每个错误选项对应的误解ID与误解名称进行映射，生成长表格式的数据。

3. **合并预测结果**：

   - 读取之前的Retriever阶段的预测结果（`oof_df.csv`），将预测的误解ID列表合并到长表数据中。

4. **调整误解ID顺序**：

   - 确保真实的误解ID在预测列表中排在前面，如果不存在，则将其插入到列表最前端并截断。

#### 数据分割

根据配置文件决定是否使用全量数据进行训练，或是按照折叠（fold）进行训练和验证数据的分割。

### 二、Retriever 阶段

#### 模型选择与配置

1. **模型选择**：
   - 采用 `Qwen2.5-32B-Instruct` 作为基础模型。
2. **LoRA 配置**：
   - 使用 LoRA（Low-Rank Adaptation）进行模型微调，以减少参数量和训练时间。
   - 配置参数包括 `r=16`, `alpha=32`, `dropout=0.00` 等，目标模块包括 `q_proj`, `k_proj`, `v_proj`,`o_proj`, `gate_proj`, `up_proj`,`down_proj`。
3. **量化配置**：
   - 使用 4-bit 量化（`BitsAndBytesConfig`）以降低显存占用，提高训练效率。

#### 数据集与数据加载

- 定义 `QPDataset` 类，将问题文本和对应的候选误解文本作为查询和通过段落输入。

- 使用 `DataLoader` 进行批量加载，定义 `collate_fn` 函数以适应数据格式。

#### 模型训练

1. **优化器与学习率调度器**：
   - 使用 `AdamW` 优化器，学习率为 `0.0001`。
   - 采用 `OneCycleLR` 调度器，设置 `max_lr=0.0001`, `total_steps` 根据训练轮数和步数计算。
2. **训练循环**：
   - 对每个批次，编码查询和候选误解文本，计算嵌入表示并进行归一化。
   - 使用对比损失（ `compute_no_in_batch_neg_loss`）计算损失，并进行反向传播和梯度更新。
3. **验证与评估**：
   - 每个训练轮结束后，进行验证集的评估，计算 MAP@25 及各个 Recall 指标（R@1, R@10, R@25, R@50, R@100）。
   - 记录并可视化训练损失和学习率变化曲线。
4. **模型保存**：
   - 训练完成后，保存微调后的模型和分词器。

### 三、Reranker 阶段

#### 模型选择与配置

1. **模型选择**：
   - 使用 `unsloth/Qwen2.5-32B-Instruct` 作为基础模型，采用 FastLanguageModel 进行高效推理。
2. **LoRA 配置**：
   - 类似 Retriever 阶段，使用 LoRA 进行模型微调，目标模块与 Retriever 阶段一致。

#### 数据预处理

1. **读取 Retriever 阶段的输出**：
   - 读取训练和验证阶段的 OOF（Out-Of-Fold）预测结果。
2. **数据增强**：
   - 对于每个样本，确保真实的误解ID包含在前5个候选误解中，如果不在，则将其加入并随机打乱顺序。
   - 将候选误解转换为对应的误解名称，并将其填充到问题文本中，形成新的输入格式。
3. **模板填充**：
   - 使用预定义的模板将问题文本和候选误解组合成指令格式，用于模型训练。

#### 模型训练

1. **训练数据集**：
   - 将预处理后的训练数据转换为 Hugging Face 的 `Dataset` 格式。
2. **训练器配置**：
   - 使用 `SFTTrainer` 进行监督微调训练（Supervised Fine-Tuning）。
   - 设置训练参数，包括批量大小、学习率、优化器类型（`adamw_8bit`）、权重衰减、学习率调度器等。
3. **训练过程**：
   - 只训练响应部分（即模型生成的误解答案），保持指令部分不变。
   - 使用 `train_on_responses_only` 函数进行训练，只优化模型的响应生成能力。
4. **模型保存**：
   - 训练完成后，保存微调后的 LoRA 模型和分词器，便于后续推理和部署。

### 四、评估与结果

#### 评估指标

- **Mean Average Precision @ 25 (MAP@25)**： 计算每个样本的前25个预测误解中真实误解的平均精度，再对所有样本取平均。
- **Recall@K (R@K)**： 计算前K个预测中包含真实误解的比例，常用的K值包括1, 10, 25, 50, 100。

#### 

#### Retriever 结果分析

在检索器阶段，使用Qwen2.5-32B-Instruct模型并结合LoRA进行微调，模型在训练集和验证集上的表现如下：

- **MAP@25**：0.4238
- **Recall@1**：0.3017
- **Recall@10**：0.6906
- **Recall@25**：0.8126
- **Recall@50**：0.8978
- **Recall@100**：0.9391

这些结果表明，检索器模型在前25位预测中包含真实误区的概率较高，尤其在Recall@50达到了89.78%，展示了模型在较大范围内的有效性。



#### Reranker 结果分析

在重排序器阶段，采用unsloth/Qwen2.5-32B-Instruct模型，通过SFTTrainer进行微调，训练过程中的关键指标如下：

- **训练损失**：0.2672
- **Kaggle公共排行榜（Public LB）**：0.54x
- **Kaggle私有排行榜（Private LB）**：0.50x

重排序器模型在提升最终的MAP@25方面发挥了关键作用，公共排行榜和私有排行榜的成绩显示了模型在实际测试中的良好泛化能力。





## **项目经验**

**Kaggle竞赛：Eedi - Mining Misconceptions in Mathematics**
*Kaggle 数据科学竞赛 | 2024年* 

- **项目简介**：参与开发自然语言处理（NLP）模型，旨在预测数学选择题中错误选项（distractors）与潜在误解（misconceptions）之间的关联，辅助教育专家高效标注误解，提高教学质量。
- **职责与贡献**：
  - **数据预处理**：使用 `polars` 库读取并转换训练集数据，将宽表格式转换为长表格式，整合问题文本和选项文本，生成统一的输入特征。
  - **模型开发**：
    - Retriever 阶段：
      - 采用 `Qwen2.5-32B-Instruct` 作为基础模型，并通过 LoRA（Low-Rank Adaptation）进行微调，优化模型参数以适应特定任务。
      - 实施4-bit量化（BitsAndBytesConfig）以提升训练效率和降低显存占用。
      - 使用对比损失函数训练模型，提升候选误解的检索准确性。
    - Reranker 阶段：
      - 使用 `unsloth/Qwen2.5-32B-Instruct` 模型进行高效推理，通过监督微调（SFTTrainer）优化误解排序，提升最终预测的准确性。
  - **评估与优化**：
    - 采用 Mean Average Precision @ 25 (MAP@25) 作为主要评估指标，结合 Recall@K 指标（K=1,10,25,50,100）全面评估模型性能。
    - 在Retriever阶段实现 MAP@25 达到0.4238，Recall@50 达到89.78%；Reranker阶段进一步优化模型，提升公共排行榜和私有排行榜的表现，展示出良好的泛化能力。
- **技术栈**：Python, NLP, 机器学习, PyTorch, LoRA, 量化技术, 数据预处理（Polars）, 对比学习, 模型微调
- **成果**：
  - 成功开发并优化了一个双阶段模型（Retriever + Reranker），显著提升了误解预测的准确性和效率。
  - 通过有效的数据处理和模型优化，实现了在验证集和隐藏测试集上的优异表现，助力模型在竞赛中获得银奖（Top 5%），Public LB 成绩为0.54x，Private LB 成绩为0.50x，展现了强大的竞争力。